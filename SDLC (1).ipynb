{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a1f1f9d3a644b64997bc44c3bf4a9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cab89e40d3349e1a62bc7603e35a7d6",
              "IPY_MODEL_11d094d87af843deae4c5745bbfb4663",
              "IPY_MODEL_b0f8d546f9d54033ad9e9e7b31a33f8f"
            ],
            "layout": "IPY_MODEL_145b9ff4f03d4ca6bac395c0b90ca894"
          }
        },
        "e8fd31a3bbc84d42851fc2b89c882120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ddb31ed793a412c82ba7cd8ae420253",
              "IPY_MODEL_5a41b3b5133b49dba533e8a1333067ab",
              "IPY_MODEL_9bbf6b801bed43b1900746de1be8f9bb"
            ],
            "layout": "IPY_MODEL_ad2842ab9c9847ee8928a01874b00325"
          }
        },
        "af0db75e89494b178c0965eb7b443f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8deb386f76664669be956bd8f5d452d6",
              "IPY_MODEL_bcb140ed1a2d4c258a7daeb6669f9f43",
              "IPY_MODEL_895305067ca44107aad43a084a5dce59"
            ],
            "layout": "IPY_MODEL_0b589bf2698e4801a648697932e63412"
          }
        },
        "9eb4458475cc4570b02b6224656cb433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ffee50a22794b6eba74af63bded9d7c",
              "IPY_MODEL_455b1a883f94468b80af7ea0a7a10f85",
              "IPY_MODEL_a732a1a5d8d0413894a5db5a46379363"
            ],
            "layout": "IPY_MODEL_289ffa4037ee43d8ab4a50a578e8eb86"
          }
        },
        "a984ed58b1454d6cacc2cd40b4a6b413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1d2ba42f57947779d3de8ea097db512",
              "IPY_MODEL_8da4b8fc6257470ab43a18d7bedb996a",
              "IPY_MODEL_7e2ed86456264763a59cd657151a25ca"
            ],
            "layout": "IPY_MODEL_daf4e9a29abb432c8c45176cfed5921c"
          }
        },
        "1477bad7a7e9449b9ac3ab3b389218b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fe5c919be9a4d0ea2643e49dfd9e3db",
              "IPY_MODEL_1c94ce296d034066bcd6bd2560c06d81",
              "IPY_MODEL_376a62af2a0c475694c51a7652c9bb1e"
            ],
            "layout": "IPY_MODEL_1cb1d11f1b924ac9b81875060f2b362c"
          }
        },
        "4eb4e65a6ec7484c85e27fd7342d331e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74514a1802464668b175c7939262e184",
              "IPY_MODEL_96681b29322d4f739a70877c3ed009b7",
              "IPY_MODEL_6a31586ff27046ebbd7ed3f26d4e493c"
            ],
            "layout": "IPY_MODEL_4c63f3f984e84dab8519055d0c9f0e54"
          }
        },
        "3918a75f86bd4213ba2eab76e113519d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8832dc7d6e27496cbcfa7b80bae81cb3",
              "IPY_MODEL_feabe8b16b9b4b6db1fc8e55034616bb",
              "IPY_MODEL_b31e143cfe874036881fb4465e75fd00"
            ],
            "layout": "IPY_MODEL_b1d268d36f6047d590c669087fcff2cd"
          }
        },
        "5ead224bb5174a63b7f5e1addc83cbd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b2485d861424b81a1b532194d3692bf",
              "IPY_MODEL_3857808a6a404ea899f59e4f8814358f",
              "IPY_MODEL_bc6230f0401a4497ab49b1a986596d53"
            ],
            "layout": "IPY_MODEL_1a39b4ea610b49f5b531bfb1c60c4237"
          }
        },
        "045e76f92de74b8c9d7c802f0470639e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c71c0acba55345c68835aa344a76bc3a",
              "IPY_MODEL_a2a22f31a4ec4e3fb8bc2133cdd38b45",
              "IPY_MODEL_023400d79dfc458abd78991be8ee3298"
            ],
            "layout": "IPY_MODEL_31572ee9796348048bbd105669e1950b"
          }
        },
        "6d7103cb952c43db9f53b28e98dde3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffd918077ae241f8bf40def8730e6cfb",
              "IPY_MODEL_9dec132f3af7415a8aca301ee4e90fd3",
              "IPY_MODEL_69976cdd364043a7a5054ecefc030aa3"
            ],
            "layout": "IPY_MODEL_209f296b97c24934af443de419efa7f7"
          }
        },
        "01b85aa71630402db6e3759b733af4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e014867272174a178f2e79690dacab5f",
              "IPY_MODEL_9140097dd13a43d08c0a33436df1f32d",
              "IPY_MODEL_f1e1a692b721495f91443f7e02f9a8eb"
            ],
            "layout": "IPY_MODEL_059818b74ced470da98a459ddec68180"
          }
        },
        "72d76b58b49b4bd0a6c83e5edf96af96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29f41e273eef4bc2abe3db56681826e8",
              "IPY_MODEL_c2c432d6168a42fe802d4496ebc672d5",
              "IPY_MODEL_2433a64084ff43e087ea36c5e62bb84f"
            ],
            "layout": "IPY_MODEL_97e0a1e979a24bc7b4abef7fe537131b"
          }
        },
        "4cb440d154c94489bfba76cb16893185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d4bdcd67384c0ebc17875b5bb14af3",
              "IPY_MODEL_baf688719b504add8b97d2c4ea3f7108",
              "IPY_MODEL_22a5f6e2b8474dd48b66cbff6ddfa546"
            ],
            "layout": "IPY_MODEL_d7bec0c9f1c2443d981865edaeb7a134"
          }
        },
        "a4d4bdcd67384c0ebc17875b5bb14af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a233a71fd952495da398ed1aa82de326",
            "placeholder": "​",
            "style": "IPY_MODEL_6d2be72d5d4b44608c3321eb8331a01e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "baf688719b504add8b97d2c4ea3f7108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f4e1befd1d84165b0d30a00fb349447",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f656b8da79d04fd2bc5530a44fbade29",
            "value": 2
          }
        },
        "22a5f6e2b8474dd48b66cbff6ddfa546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc6cab2adb7442e9398f1e5e81dede6",
            "placeholder": "​",
            "style": "IPY_MODEL_735742c1161e43faad4e5c3173a15257",
            "value": " 2/2 [00:01&lt;00:00,  1.81s/it]"
          }
        },
        "d7bec0c9f1c2443d981865edaeb7a134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a233a71fd952495da398ed1aa82de326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2be72d5d4b44608c3321eb8331a01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4e1befd1d84165b0d30a00fb349447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f656b8da79d04fd2bc5530a44fbade29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bc6cab2adb7442e9398f1e5e81dede6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735742c1161e43faad4e5c3173a15257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f0c6ade5f984237bd53567abd91ad80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1bb2372df884e4cafd326726b6b40c7",
              "IPY_MODEL_888591cb6ad84a358d2b4ec30cc3eca6",
              "IPY_MODEL_d6c33c9b59d64bd28e6f45e2a43793be"
            ],
            "layout": "IPY_MODEL_07941cec15c749beb1cd64e70d123319"
          }
        },
        "a1bb2372df884e4cafd326726b6b40c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8324ee45fd934a7fbba4fadf234d6bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_e3dd2a0d3d4e4fe8894f89bf76f1e334",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "888591cb6ad84a358d2b4ec30cc3eca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da79ba0d74b442309e28abf10d69842e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be9368f4b2f84fc5a7b3ab74e763e4d3",
            "value": 2
          }
        },
        "d6c33c9b59d64bd28e6f45e2a43793be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc174ce1eb744f9b73e82199b42ce40",
            "placeholder": "​",
            "style": "IPY_MODEL_2308175dec3241e584291d794cde5057",
            "value": " 2/2 [00:01&lt;00:00,  1.82s/it]"
          }
        },
        "07941cec15c749beb1cd64e70d123319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8324ee45fd934a7fbba4fadf234d6bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3dd2a0d3d4e4fe8894f89bf76f1e334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da79ba0d74b442309e28abf10d69842e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9368f4b2f84fc5a7b3ab74e763e4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cc174ce1eb744f9b73e82199b42ce40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2308175dec3241e584291d794cde5057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I7gtBaCPdNw4",
        "outputId": "57a7691a-f539-452d-9f99-672242d4cd65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch gradio PyPDF2 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import PyPDF2\n",
        "import io\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"ibm-granite/granite-3.2-2b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_response(prompt, max_length=1024):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.replace(prompt, \"\").strip()\n",
        "    return response\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    if pdf_file is None:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {str(e)}\"\n",
        "\n",
        "def requirement_analysis(pdf_file, prompt_text):\n",
        "    # Get text from PDF or prompt\n",
        "    if pdf_file is not None:\n",
        "        content = extract_text_from_pdf(pdf_file)\n",
        "        analysis_prompt = f\"Analyze the following document and extract key software requirements. Organize them into functional requirements, non-functional requirements, and technical specifications:\\n\\n{content}\"\n",
        "    else:\n",
        "        analysis_prompt = f\"Analyze the following requirements and organize them into functional requirements, non-functional requirements, and technical specifications:\\n\\n{prompt_text}\"\n",
        "\n",
        "    return generate_response(analysis_prompt, max_length=1200)\n",
        "\n",
        "def code_generation(prompt, language):\n",
        "    code_prompt = f\"Generate {language} code for the following requirement:\\n\\n{prompt}\\n\\nCode:\"\n",
        "    return generate_response(code_prompt, max_length=1200)\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# AI Code Analysis & Generator\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Code Analysis\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    pdf_upload = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "                    prompt_input = gr.Textbox(\n",
        "                        label=\"Or write requirements here\",\n",
        "                        placeholder=\"Describe your software requirements...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    analyze_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    analysis_output = gr.Textbox(label=\"Requirements Analysis\", lines=20)\n",
        "\n",
        "            analyze_btn.click(requirement_analysis, inputs=[pdf_upload, prompt_input], outputs=analysis_output)\n",
        "\n",
        "        with gr.TabItem(\"Code Generation\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    code_prompt = gr.Textbox(\n",
        "                        label=\"Code Requirements\",\n",
        "                        placeholder=\"Describe what code you want to generate...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    language_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Python\", \"JavaScript\", \"Java\", \"C++\", \"C#\", \"PHP\", \"Go\", \"Rust\"],\n",
        "                        label=\"Programming Language\",\n",
        "                        value=\"Python\"\n",
        "                    )\n",
        "                    generate_btn = gr.Button(\"Generate Code\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    code_output = gr.Textbox(label=\"Generated Code\", lines=20)\n",
        "\n",
        "            generate_btn.click(code_generation, inputs=[code_prompt, language_dropdown], outputs=code_output)\n",
        "\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732,
          "referenced_widgets": [
            "0a1f1f9d3a644b64997bc44c3bf4a9be",
            "e8fd31a3bbc84d42851fc2b89c882120",
            "af0db75e89494b178c0965eb7b443f21",
            "9eb4458475cc4570b02b6224656cb433",
            "a984ed58b1454d6cacc2cd40b4a6b413",
            "1477bad7a7e9449b9ac3ab3b389218b7",
            "4eb4e65a6ec7484c85e27fd7342d331e",
            "3918a75f86bd4213ba2eab76e113519d",
            "5ead224bb5174a63b7f5e1addc83cbd2",
            "045e76f92de74b8c9d7c802f0470639e",
            "6d7103cb952c43db9f53b28e98dde3a7",
            "01b85aa71630402db6e3759b733af4b3",
            "72d76b58b49b4bd0a6c83e5edf96af96"
          ]
        },
        "id": "YvPyFEqCe5u_",
        "outputId": "1e71225a-4f35-465c-b50b-bfef3f552a7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a1f1f9d3a644b64997bc44c3bf4a9be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8fd31a3bbc84d42851fc2b89c882120"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af0db75e89494b178c0965eb7b443f21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eb4458475cc4570b02b6224656cb433"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a984ed58b1454d6cacc2cd40b4a6b413"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1477bad7a7e9449b9ac3ab3b389218b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/786 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eb4e65a6ec7484c85e27fd7342d331e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3918a75f86bd4213ba2eab76e113519d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ead224bb5174a63b7f5e1addc83cbd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "045e76f92de74b8c9d7c802f0470639e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d7103cb952c43db9f53b28e98dde3a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01b85aa71630402db6e3759b733af4b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72d76b58b49b4bd0a6c83e5edf96af96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b58e668c46efa3b9a2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b58e668c46efa3b9a2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import PyPDF2\n",
        "import io\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"ibm-granite/granite-3.2-2b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_response(prompt, max_length=1024):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.replace(prompt, \"\").strip()\n",
        "    return response\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    if pdf_file is None:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {str(e)}\"\n",
        "\n",
        "def requirement_analysis(pdf_file, prompt_text):\n",
        "    # Get text from PDF or prompt\n",
        "    if pdf_file is not None:\n",
        "        content = extract_text_from_pdf(pdf_file)\n",
        "        analysis_prompt = f\"Analyze the following document and extract key software requirements. Organize them into functional requirements, non-functional requirements, and technical specifications:\\n\\n{content}\"\n",
        "    else:\n",
        "        analysis_prompt = f\"Analyze the following requirements and organize them into functional requirements, non-functional requirements, and technical specifications:\\n\\n{prompt_text}\"\n",
        "\n",
        "    return generate_response(analysis_prompt, max_length=1200)\n",
        "\n",
        "def code_generation(prompt, language):\n",
        "    code_prompt = f\"Generate {language} code for the following requirement:\\n\\n{prompt}\\n\\nCode:\"\n",
        "    return generate_response(code_prompt, max_length=1200)\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# AI Code Analysis & Generator\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Code Analysis\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    pdf_upload = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "                    prompt_input = gr.Textbox(\n",
        "                        label=\"Or write requirements here\",\n",
        "                        placeholder=\"Describe your software requirements...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    analyze_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    analysis_output = gr.Textbox(label=\"Requirements Analysis\", lines=20)\n",
        "\n",
        "            analyze_btn.click(requirement_analysis, inputs=[pdf_upload, prompt_input], outputs=analysis_output)\n",
        "\n",
        "        with gr.TabItem(\"Code Generation\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    code_prompt = gr.Textbox(\n",
        "                        label=\"Code Requirements\",\n",
        "                        placeholder=\"Describe what code you want to generate...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    language_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Python\", \"JavaScript\", \"Java\", \"C++\", \"C#\", \"PHP\", \"Go\", \"Rust\"],\n",
        "                        label=\"Programming Language\",\n",
        "                        value=\"Python\"\n",
        "                    )\n",
        "                    generate_btn = gr.Button(\"Generate Code\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    code_output = gr.Textbox(label=\"Generated Code\", lines=20)\n",
        "\n",
        "            generate_btn.click(code_generation, inputs=[code_prompt, language_dropdown], outputs=code_output)\n",
        "\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643,
          "referenced_widgets": [
            "4cb440d154c94489bfba76cb16893185",
            "a4d4bdcd67384c0ebc17875b5bb14af3",
            "baf688719b504add8b97d2c4ea3f7108",
            "22a5f6e2b8474dd48b66cbff6ddfa546",
            "d7bec0c9f1c2443d981865edaeb7a134",
            "a233a71fd952495da398ed1aa82de326",
            "6d2be72d5d4b44608c3321eb8331a01e",
            "1f4e1befd1d84165b0d30a00fb349447",
            "f656b8da79d04fd2bc5530a44fbade29",
            "8bc6cab2adb7442e9398f1e5e81dede6",
            "735742c1161e43faad4e5c3173a15257"
          ]
        },
        "id": "HN3diA0cgiDX",
        "outputId": "4b903dc4-5931-41f8-8865-4bfaf9deba2c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cb440d154c94489bfba76cb16893185"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2d63b5ed9f284e6912.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2d63b5ed9f284e6912.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import PyPDF2\n",
        "import io\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"ibm-granite/granite-3.2-2b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_response(prompt, max_length=1024):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.replace(prompt, \"\").strip()\n",
        "    return response\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    if pdf_file is None:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {str(e)}\"\n",
        "\n",
        "def eco_tips_generator(problem_keywords):\n",
        "    prompt = f\"generate practical and actionable eco-friendly tips for sustainable living related to: {problem_keywords}. provide specific solutions and suggestions:\"\n",
        "    return generate_response(prompt, max_length=1000)\n",
        "\n",
        "def policy_summerization(pdf_file, policy_text):\n",
        "    # Get text from PDF or direct input\n",
        "    if pdf_file is not None:\n",
        "        content = extract_text_from_pdf(pdf_file)\n",
        "        summary_prompt = f\"summerize the following policy document and extract the most important points, key provisions, and implications:\\n\\n{content}\"\n",
        "    else:\n",
        "\n",
        "\n",
        "    return generate_response(analysis_prompt, max_length=1200)\n",
        "\n",
        "def code_generation(prompt, language):\n",
        "    code_prompt = f\"Generate {language} code for the following requirement:\\n\\n{prompt}\\n\\nCode:\"\n",
        "    return generate_response(code_prompt, max_length=1200)\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# AI Code Analysis & Generator\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Code Analysis\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    pdf_upload = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "                    prompt_input = gr.Textbox(\n",
        "                        label=\"Or write requirements here\",\n",
        "                        placeholder=\"Describe your software requirements...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    analyze_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    analysis_output = gr.Textbox(label=\"Requirements Analysis\", lines=20)\n",
        "\n",
        "            analyze_btn.click(requirement_analysis, inputs=[pdf_upload, prompt_input], outputs=analysis_output)\n",
        "\n",
        "        with gr.TabItem(\"Code Generation\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    code_prompt = gr.Textbox(\n",
        "                        label=\"Code Requirements\",\n",
        "                        placeholder=\"Describe what code you want to generate...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    language_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Python\", \"JavaScript\", \"Java\", \"C++\", \"C#\", \"PHP\", \"Go\", \"Rust\"],\n",
        "                        label=\"Programming Language\",\n",
        "                        value=\"Python\"\n",
        "                    )\n",
        "                    generate_btn = gr.Button(\"Generate Code\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    code_output = gr.Textbox(label=\"Generated Code\", lines=20)\n",
        "\n",
        "            generate_btn.click(code_generation, inputs=[code_prompt, language_dropdown], outputs=code_output)\n",
        "\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643,
          "referenced_widgets": [
            "4f0c6ade5f984237bd53567abd91ad80",
            "a1bb2372df884e4cafd326726b6b40c7",
            "888591cb6ad84a358d2b4ec30cc3eca6",
            "d6c33c9b59d64bd28e6f45e2a43793be",
            "07941cec15c749beb1cd64e70d123319",
            "8324ee45fd934a7fbba4fadf234d6bf2",
            "e3dd2a0d3d4e4fe8894f89bf76f1e334",
            "da79ba0d74b442309e28abf10d69842e",
            "be9368f4b2f84fc5a7b3ab74e763e4d3",
            "6cc174ce1eb744f9b73e82199b42ce40",
            "2308175dec3241e584291d794cde5057"
          ]
        },
        "id": "kpX3beyRlB6Z",
        "outputId": "8c139e3b-2f00-4659-8328-b2ab5c24b074"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f0c6ade5f984237bd53567abd91ad80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://93119003fcd5f34782.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://93119003fcd5f34782.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import PyPDF2\n",
        "import io\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"ibm-granite/granite-3.2-2b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_response(prompt, max_length=1024):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.replace(prompt, \"\").strip()\n",
        "    return response\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    if pdf_file is None:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {str(e)}\"\n",
        "\n",
        "def eco_tips_generator(problem_keywords):\n",
        "    prompt = f\"generate practical and actionable eco-friendly tips for sustainable living related to: {problem_keywords}. provide specific solutions and suggestions:\"\n",
        "    return generate_response(prompt, max_length=1000)\n",
        "\n",
        "def policy_summerization(pdf_file, policy_text):\n",
        "    # Get text from PDF or direct input\n",
        "    if pdf_file is not None:\n",
        "        content = extract_text_from_pdf(pdf_file)\n",
        "        summary_prompt = f\"summerize the following policy document and extract the most important points, key provisions, and implications:\\n\\n{content}\"\n",
        "    else:\n",
        "\n",
        "\n",
        "    return generate_response(analysis_prompt, max_length=1200)\n",
        "\n",
        "def code_generation(prompt, language):\n",
        "    code_prompt = f\"Generate {language} code for the following requirement:\\n\\n{prompt}\\n\\nCode:\"\n",
        "    return generate_response(code_prompt, max_length=1200)\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# AI Code Analysis & Generator\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Code Analysis\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    pdf_upload = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "                    prompt_input = gr.Textbox(\n",
        "                        label=\"Or write requirements here\",\n",
        "                        placeholder=\"Describe your software requirements...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    analyze_btn = gr.Button(\"Analyze\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    analysis_output = gr.Textbox(label=\"Requirements Analysis\", lines=20)\n",
        "\n",
        "            analyze_btn.click(requirement_analysis, inputs=[pdf_upload, prompt_input], outputs=analysis_output)\n",
        "\n",
        "        with gr.TabItem(\"Code Generation\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    code_prompt = gr.Textbox(\n",
        "                        label=\"Code Requirements\",\n",
        "                        placeholder=\"Describe what code you want to generate...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    language_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Python\", \"JavaScript\", \"Java\", \"C++\", \"C#\", \"PHP\", \"Go\", \"Rust\"],\n",
        "                        label=\"Programming Language\",\n",
        "                        value=\"Python\"\n",
        "                    )\n",
        "                    generate_btn = gr.Button(\"Generate Code\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    code_output = gr.Textbox(label=\"Generated Code\", lines=20)\n",
        "\n",
        "            generate_btn.click(code_generation, inputs=[code_prompt, language_dropdown], outputs=code_output)\n",
        "\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "outputId": "8c139e3b-2f00-4659-8328-b2ab5c24b074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643,
          "referenced_widgets": [
            "4f0c6ade5f984237bd53567abd91ad80",
            "a1bb2372df884e4cafd326726b6b40c7",
            "888591cb6ad84a358d2b4ec30cc3eca6",
            "d6c33c9b59d64bd28e6f45e2a43793be",
            "07941cec15c749beb1cd64e70d123319",
            "8324ee45fd934a7fbba4fadf234d6bf2",
            "e3dd2a0d3d4e4fe8894f89bf76f1e334",
            "da79ba0d74b442309e28abf10d69842e",
            "be9368f4b2f84fc5a7b3ab74e763e4d3",
            "6cc174ce1eb744f9b73e82199b42ce40",
            "2308175dec3241e584291d794cde5057"
          ]
        },
        "id": "mg015hKVv-iC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f0c6ade5f984237bd53567abd91ad80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://93119003fcd5f34782.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://93119003fcd5f34782.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import PyPDF2\n",
        "import io\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"ibm-granite/granite-3.2-2b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_response(prompt, max_length=1024):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.replace(prompt, \"\").strip()\n",
        "    return response\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    if pdf_file is None:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {str(e)}\"\n",
        "\n",
        "def eco_tips_generator(problem_keywords):\n",
        "    prompt = f\"generate practical and actionable eco-friendly tips for sustainable living related to: {problem_keywords}. provide specific solutions and suggestions:\"\n",
        "    return generate_response(prompt, max_length=1000)\n",
        "\n",
        "def policy_summerization(pdf_file, policy_text):\n",
        "    # Get text from PDF or direct input\n",
        "    if pdf_file is not None:\n",
        "        content = extract_text_from_pdf(pdf_file)\n",
        "        summary_prompt = f\"summerize the following policy document and extract the most important points, key provisions, and implications:\\n\\n{content}\"\n",
        "    else:\n",
        "        summary_prompt = f\"summarize the following policy document and extract the most important points, key provisions, and implications:\\n\\n{policy_text}\"\n",
        "\n",
        "    return generate_response(summary_prompt, max_length=1200)\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Eco Assistant & Policy Analyzer\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Eco Tips Generator\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    keyword_input = gr.textbox(\n",
        "                        label=\"Environmental Problem/Keywords\",\n",
        "                        placeholder=\"e.g., plastic, solar, water waste, energy saving...\",\n",
        "                        lines=3\n",
        "                    )\n",
        "                    generate_tips_btn = gr.Button(\"Generate Eco Tips\")\n",
        "\n",
        "        with gr.TabItem(\"policy summarization\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    pdf_upload = gr.File(label=\"Upload Policy PDF\", file_types=[\".pdf\"])\n",
        "                    policy_text_input = gr.Textbox(\n",
        "                        label=\"Or paste policy text here\",\n",
        "                        placeholder=\"paste policy document text...\",\n",
        "                        lines=5\n",
        "                    )\n",
        "                    summarize_btn = gr.Button(\"summarize policy\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    summarize_output = gr.Textbox(label=\"policy summary & key points\", lines=20)\n",
        "\n",
        "            summarize_btn.click(policy_summarization, inputs=[pdf_upload, policy_text_input], outputs=summary_output)\n",
        "\n",
        "\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "outputId": "5d1086fd-b739-41f6-ea9b-a141c5412c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "lnyPxbqSwIZR"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'PyPDF2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1553320231.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}